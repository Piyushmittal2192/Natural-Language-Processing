{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t0D_p9Oza5o6"
   },
   "source": [
    "\n",
    "# Question and Answer Chat Bots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y5Jw8AAja5o-"
   },
   "source": [
    "## Loading the Data\n",
    "\n",
    "We will be working with the Babi Data Set from Facebook Research.\n",
    "\n",
    "Full Details: https://research.fb.com/downloads/babi/\n",
    "\n",
    "- Jason Weston, Antoine Bordes, Sumit Chopra, Tomas Mikolov, Alexander M. Rush,\n",
    "  \"Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks\",\n",
    "  http://arxiv.org/abs/1502.05698\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3AaGJVfza5pA"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h-9KW2txa5pG"
   },
   "outputs": [],
   "source": [
    "with open(\"train_qa.txt\", \"rb\") as fp:   # Unpickling\n",
    "    train_data =  pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oZ2vuF3ua5pM"
   },
   "outputs": [],
   "source": [
    "with open(\"test_qa.txt\", \"rb\") as fp:   # Unpickling\n",
    "    test_data =  pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j7iuIL3Ha5pR"
   },
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VohzJNAia5pT"
   },
   "source": [
    "### Tip: It may be a good idea to explore the dataset!\n",
    "\n",
    "Below is just a sample of what you can do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "j3BlD0zga5pV",
    "outputId": "d008dd83-d4bd-4850-877f-8ff2bdd61b90"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "7_PWJptea5pn",
    "outputId": "291678f3-62e9-4bac-bc7c-9f3614713fdf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "UfflSXlNa5ps",
    "outputId": "f7ed2c2d-0a26-43ac-b8c8-c63676555cc2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Mary',\n",
       "  'moved',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bathroom',\n",
       "  '.',\n",
       "  'Sandra',\n",
       "  'journeyed',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bedroom',\n",
       "  '.'],\n",
       " ['Is', 'Sandra', 'in', 'the', 'hallway', '?'],\n",
       " 'no')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bR7lT-UNa5qD"
   },
   "source": [
    "-----\n",
    "\n",
    "## Setting up Vocabulary of All Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lPHxf3JXa5qE"
   },
   "outputs": [],
   "source": [
    "# Create a set that holds the vocab words\n",
    "vocab = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yroUGLs7a5qK"
   },
   "outputs": [],
   "source": [
    "all_data = test_data + train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DSnJXuz1a5qQ"
   },
   "outputs": [],
   "source": [
    "for story, question , answer in all_data:\n",
    "    # In case you don't know what a union of sets is:\n",
    "    # https://www.programiz.com/python-programming/methods/set/union\n",
    "    vocab = vocab.union(set(story))\n",
    "    vocab = vocab.union(set(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T0V4ALeAa5qV"
   },
   "outputs": [],
   "source": [
    "# Include any other words in the bot's vocabulary\n",
    "vocab.add('no')\n",
    "vocab.add('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 646
    },
    "colab_type": "code",
    "id": "X37F4gEZa5qa",
    "outputId": "df8fdcbe-8aa0-4d8f-a3f6-3b307701d882"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SmUOXfRva5qe"
   },
   "outputs": [],
   "source": [
    "vocab_len = len(vocab) + 1 #we add an extra space to hold a 0 for Keras's pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TAH0SnYYa5qj"
   },
   "outputs": [],
   "source": [
    "max_story_len = max([len(data[0]) for data in all_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "5fbcSZGQa5qp",
    "outputId": "3db893eb-0ff5-4d07-93d5-1f825b785ceb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_story_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zsZFkb7ra5q0"
   },
   "outputs": [],
   "source": [
    "max_question_len = max([len(data[1]) for data in all_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "xLD1Pyl4a5q7",
    "outputId": "019916b7-ce15-4569-8026-8a7b6d5fc606"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_question_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3ZlHWiyda5q_"
   },
   "source": [
    "## Vectorizing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 646
    },
    "colab_type": "code",
    "id": "38vgdT3Ma5rA",
    "outputId": "43aa1187-0acf-44b7-b8bb-62a0f1a25647"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6VASh8nIa5rF"
   },
   "outputs": [],
   "source": [
    "# Reserve 0 for pad_sequences\n",
    "vocab_size = len(vocab) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G-if2LNba5rM"
   },
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 97
    },
    "colab_type": "code",
    "id": "KZ4IS6a6a5rN",
    "outputId": "f01f4f79-6896-4878-c9db-412777d4f8ee"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8B1PWhoFa5rQ"
   },
   "outputs": [],
   "source": [
    "# integer encode sequences of words\n",
    "tokenizer = Tokenizer(filters=[])\n",
    "\n",
    "# TODO: Fit tokenizer on text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for text in all_data:\n",
    "    #print(text)\n",
    "    tokenizer.fit_on_texts(text)\n",
    "\n",
    "#tk.fit_on_texts(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 1,\n",
       " '.': 2,\n",
       " 'to': 3,\n",
       " 'sandra': 4,\n",
       " 'mary': 5,\n",
       " 'daniel': 6,\n",
       " 'john': 7,\n",
       " 'went': 8,\n",
       " 'there': 9,\n",
       " 'is': 10,\n",
       " 'in': 11,\n",
       " '?': 12,\n",
       " 'bedroom': 13,\n",
       " 'kitchen': 14,\n",
       " 'office': 15,\n",
       " 'hallway': 16,\n",
       " 'journeyed': 17,\n",
       " 'garden': 18,\n",
       " 'travelled': 19,\n",
       " 'bathroom': 20,\n",
       " 'moved': 21,\n",
       " 'back': 22,\n",
       " 'milk': 23,\n",
       " 'apple': 24,\n",
       " 'football': 25,\n",
       " 'yes': 26,\n",
       " 'no': 27,\n",
       " 'got': 28,\n",
       " 'picked': 29,\n",
       " 'up': 30,\n",
       " 'took': 31,\n",
       " 'grabbed': 32,\n",
       " 'discarded': 33,\n",
       " 'dropped': 34,\n",
       " 'put': 35,\n",
       " 'down': 36,\n",
       " 'left': 37}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 646
    },
    "colab_type": "code",
    "id": "83AGtmI4a5rT",
    "outputId": "b3062e37-b68a-43b9-ccdf-1940b647cec2"
   },
   "outputs": [],
   "source": [
    "#tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qc0-V6aMa5rc"
   },
   "outputs": [],
   "source": [
    "train_story_text = []\n",
    "train_question_text = []\n",
    "train_answers = []\n",
    "\n",
    "# TODO: Fill the story, question, and answers list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for story in train_data.copy():\n",
    "    train_story_text.append(story[0])\n",
    "    train_question_text.append(story[1])\n",
    "    train_answers.append(story[2])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_question_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Mary',\n",
       "  'moved',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bathroom',\n",
       "  '.',\n",
       "  'Sandra',\n",
       "  'journeyed',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bedroom',\n",
       "  '.'],\n",
       " ['Mary',\n",
       "  'moved',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bathroom',\n",
       "  '.',\n",
       "  'Sandra',\n",
       "  'journeyed',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bedroom',\n",
       "  '.',\n",
       "  'Mary',\n",
       "  'went',\n",
       "  'back',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bedroom',\n",
       "  '.',\n",
       "  'Daniel',\n",
       "  'went',\n",
       "  'back',\n",
       "  'to',\n",
       "  'the',\n",
       "  'hallway',\n",
       "  '.']]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_story_text[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pse59hvwa5rg"
   },
   "outputs": [],
   "source": [
    "# TODO: Vectorize into word sequences.\n",
    "#train_story_text[0][0].lower()\n",
    "train_story_seq = []\n",
    "import copy\n",
    "train_text = copy.deepcopy(train_story_text)\n",
    "for idx, i in enumerate(train_text):\n",
    "    train_story_text_vec = []\n",
    "    #print(i.lower())\n",
    "    train_story_text_vec = i\n",
    "    for jdx, j in enumerate(i):\n",
    "        if j.lower() in tokenizer.word_index.keys():\n",
    "            train_story_text_vec[jdx] = tokenizer.word_index[j.lower()]\n",
    "    train_story_seq.append(train_story_text_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 1,\n",
       " '.': 2,\n",
       " 'to': 3,\n",
       " 'sandra': 4,\n",
       " 'mary': 5,\n",
       " 'daniel': 6,\n",
       " 'john': 7,\n",
       " 'went': 8,\n",
       " 'there': 9,\n",
       " 'is': 10,\n",
       " 'in': 11,\n",
       " '?': 12,\n",
       " 'bedroom': 13,\n",
       " 'kitchen': 14,\n",
       " 'office': 15,\n",
       " 'hallway': 16,\n",
       " 'journeyed': 17,\n",
       " 'garden': 18,\n",
       " 'travelled': 19,\n",
       " 'bathroom': 20,\n",
       " 'moved': 21,\n",
       " 'back': 22,\n",
       " 'milk': 23,\n",
       " 'apple': 24,\n",
       " 'football': 25,\n",
       " 'yes': 26,\n",
       " 'no': 27,\n",
       " 'got': 28,\n",
       " 'picked': 29,\n",
       " 'up': 30,\n",
       " 'took': 31,\n",
       " 'grabbed': 32,\n",
       " 'discarded': 33,\n",
       " 'dropped': 34,\n",
       " 'put': 35,\n",
       " 'down': 36,\n",
       " 'left': 37}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "wdPIW9Fja5rk",
    "outputId": "86b96d78-48c8-4f54-b38f-a11aa7264001"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_story_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6Hc0L1-Ja5ru",
    "outputId": "1b2b03e5-ddf8-4f20-f538-f76af7c050f6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_story_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-3GCN3cva5sC"
   },
   "source": [
    "### Functionalize Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mary', 'moved', 'to', 'the', 'bathroom', '.', 'Sandra', 'journeyed', 'to', 'the', 'bedroom', '.']\n",
      "['Mary', 'moved', 'to', 'the', 'bathroom', '.', 'Sandra', 'journeyed', 'to', 'the', 'bedroom', '.', 'Mary', 'went', 'back', 'to', 'the', 'bedroom', '.', 'Daniel', 'went', 'back', 'to', 'the', 'hallway', '.']\n"
     ]
    }
   ],
   "source": [
    "for story, query, answer in train_data[0:2].copy():\n",
    "    print(story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XIm6vjlca5sE"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "def vectorize_stories(data, \n",
    "                      word_index=tokenizer.word_index, \n",
    "                      max_story_len=max_story_len,\n",
    "                      max_question_len=max_question_len):\n",
    "    '''\n",
    "    INPUT: \n",
    "    \n",
    "    data: consisting of Stories,Queries,and Answers\n",
    "    word_index: word index dictionary from tokenizer\n",
    "    max_story_len: the length of the longest story (used for pad_sequences function)\n",
    "    max_question_len: length of the longest question (used for pad_sequences function)\n",
    "\n",
    "\n",
    "    OUTPUT:\n",
    "    \n",
    "    Vectorizes the stories,questions, and answers into padded sequences. We first loop for every story, query , and\n",
    "    answer in the data. Then we convert the raw words to an word index value. Then we append each set to their appropriate\n",
    "    output list. Then once we have converted the words to numbers, we pad the sequences so they are all of equal length.\n",
    "    \n",
    "    Returns this in the form of a tuple (X,Xq,Y) (padded based on max lengths)\n",
    "    '''\n",
    "    \n",
    "    dataset = copy.deepcopy(data)\n",
    "    X = []\n",
    "    # Xq = QUERY/QUESTION\n",
    "    Xq = []\n",
    "    # Y = CORRECT ANSWER\n",
    "    Y = []\n",
    "    word_index=tokenizer.word_index\n",
    "    \n",
    "    '''\n",
    "    for story, query, answer in dataset:\n",
    "        Y.append(answer)\n",
    "    l = list(set(Y))\n",
    "    Y = []  \n",
    "\n",
    "    en = np.array( [ word_index[l[0]] , word_index[l[1]] ] )\n",
    "\n",
    "    encoded = to_categorical(en)\n",
    "    '''\n",
    "    \n",
    "    for story, query, answer in dataset:\n",
    "        x = story\n",
    "        xq = query\n",
    "        y = answer\n",
    "\n",
    "        # TODO: Store every word from story into a list\n",
    "        # TODO: Store every word from query into a list\n",
    "\n",
    "        # TODO: One-hot encode the label into a list\n",
    "        x = [word_index[j.lower()] for j in story]\n",
    "        xq = [word_index[j.lower()] for j in query]\n",
    "        #y = encoded[en == word_index[answer.lower()]]\n",
    "        \n",
    "        y = word_index[answer.lower()]\n",
    "\n",
    "        # Append each set of story,query, and answer to their respective holding lists\n",
    "        X.append(x)\n",
    "        Xq.append(xq)\n",
    "        Y.append(y)\n",
    "    \n",
    "\n",
    "        \n",
    "    # RETURN TUPLE of paded, uniform sequences FOR UNPACKING\n",
    "    return (pad_sequences(X, maxlen=max_story_len),pad_sequences(Xq, maxlen=max_question_len), np.array(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8iFoz6nVa5sP"
   },
   "outputs": [],
   "source": [
    "inputs_train, queries_train, answers_train = vectorize_stories(data = train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eejFwvhua5sS"
   },
   "outputs": [],
   "source": [
    "inputs_test, queries_test, answers_test = vectorize_stories(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "4cf-rfn1a5st",
    "outputId": "3083bd03-df1e-48f2-ce48-9d383bcd045b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index['yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Bediffima5sy",
    "outputId": "ff73f609-a3f5-4b62-b3ea-4be180f02020"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index['no']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vu6Xo-Noa5s5"
   },
   "source": [
    "## Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wFESvEZsa5s8"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Input, Activation, Dense, Permute, Dropout, Reshape\n",
    "from keras.layers import add, dot, concatenate\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "word2vec = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6-YOF6oDa5tG"
   },
   "source": [
    "### Placeholders for Inputs\n",
    "\n",
    "Recall we technically have two inputs, stories and questions. So we need to use placeholders. `Input()` is used to instantiate a Keras tensor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 300\n",
    "word_index = tokenizer.word_index\n",
    "embeddings = 1 * np.random.randn(len(word_index) + 1, embedding_dim)  # This will be the embedding matrix\n",
    "embeddings[0] = 0  # So that the padding will be ignored\n",
    "\n",
    "# Build the embedding matrix\n",
    "for word, index in word_index.items():\n",
    "    if word in word2vec.vocab:\n",
    "        embeddings[index] = word2vec.word_vec(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "TqCPMwsla5tH",
    "outputId": "fa35f698-ad11-4710-897d-cd5f3e5051d7"
   },
   "outputs": [],
   "source": [
    "input_sequence = Input((max_story_len,))\n",
    "question = Input((max_question_len,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "JOkE0wwga5tN"
   },
   "source": [
    "### Building the Networks\n",
    "\n",
    "To understand why we chose this setup, make sure to read the paper we are using:\n",
    "\n",
    "* Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston, Rob Fergus,\n",
    "  \"End-To-End Memory Networks\",\n",
    "  http://arxiv.org/abs/1503.08895"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37, 38)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab), len(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7NJeRFIta5tP"
   },
   "source": [
    "## Encoders\n",
    "\n",
    "The input to your neural network for an NLP task requires you to setup an Embedding layer which creates word embedding for you(aka word2vec).\n",
    "\n",
    "Also it would be a good idea to experiment with different hyperparameters like using/not using dropout layers, learning rate etc\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c_7fsR9rMFY0"
   },
   "source": [
    "### Input Encoder m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "lIUWSinPa5tR",
    "outputId": "fa79eb28-c4a4-4d16-e94c-7c3dbf5bae1e"
   },
   "outputs": [],
   "source": [
    "# Input gets embedded to a sequence of vectors\n",
    "input_encoder_m = Sequential()\n",
    "input_encoder_m.add(Embedding(input_dim=vocab_size,output_dim=embedding_dim,  weights=[embeddings]))\n",
    "\n",
    "#input_encoder_m.add(Reshape((embedding_dim, )))\n",
    "\n",
    "# Optional: Create any additional layers for neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 300)         11400     \n",
      "=================================================================\n",
      "Total params: 11,400\n",
      "Trainable params: 11,400\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_encoder_m.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RQEqTIala5tW"
   },
   "source": [
    "### Input Encoder c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JF3erOIXa5tY"
   },
   "outputs": [],
   "source": [
    "# Embed the input into a sequence of vectors of size query_maxlen\n",
    "input_encoder_c = Sequential()\n",
    "input_encoder_c.add(Embedding(input_dim=vocab_size,output_dim=max_question_len))\n",
    "\n",
    "# Optional: Create any additional layers for neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 6)           228       \n",
      "=================================================================\n",
      "Total params: 228\n",
      "Trainable params: 228\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_encoder_c.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ii7TEQLHa5ti"
   },
   "source": [
    "### Question Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qt9kKE3La5tj"
   },
   "outputs": [],
   "source": [
    "# embed the question into a sequence of vectors\n",
    "question_encoder = Sequential()\n",
    "question_encoder.add(Embedding(input_dim=vocab_size,\n",
    "                               output_dim=embedding_dim,\n",
    "                               input_length=max_question_len,\n",
    "                              weights=[embeddings]))\n",
    "#question_encoder.add(Reshape((embedding_dim,max_question_len )))\n",
    "# Optional: Create any additional layers for neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 6, 300)            11400     \n",
      "=================================================================\n",
      "Total params: 11,400\n",
      "Trainable params: 11,400\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "question_encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x_I8ywjDa5to"
   },
   "source": [
    "### Encode the Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ap2fFowPa5tp"
   },
   "outputs": [],
   "source": [
    "# TODO: Encode input sequence and questions (which are indices)\n",
    "# to sequences of dense vectors\n",
    "\n",
    "encoded_story = input_encoder_m(input_sequence)\n",
    "encoded_question = question_encoder(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YJgN7i1aa5tv"
   },
   "source": [
    "##### Use dot product to compute the match between first input vector seq and the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f_W9OTBca5ty"
   },
   "outputs": [],
   "source": [
    "# shape: `(samples, story_maxlen, query_maxlen)`\n",
    "\n",
    "dot_product = dot([encoded_story, encoded_question], axes=-1, normalize=False)\n",
    "output = Activation('softmax')(dot_product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 156, 6])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot_product.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 156, 6])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bnQcWYIja5t2"
   },
   "source": [
    "#### Add this match matrix with the second input vector sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qq6d15Yba5t3"
   },
   "outputs": [],
   "source": [
    "# Add the match matrix with the second input vector sequence\n",
    "encoded_c = input_encoder_c(input_sequence)\n",
    "response =  add([output, encoded_c])\n",
    "response = Permute((2, 1))(response)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xqv0cWNBa5t9"
   },
   "source": [
    "#### Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5TfL3iy1a5t_"
   },
   "outputs": [],
   "source": [
    "# Concatenate the match matrix with the question vector sequence\n",
    "answer = concatenate([response, encoded_question])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Klww8nV0a5uG",
    "outputId": "8be4f854-2d53-4f4f-ffc4-0e1e473dc02b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 6, 456])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = LSTM(32)(answer)  # (samples, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4_B3i2n_a5uO"
   },
   "outputs": [],
   "source": [
    "# Regularization with Dropout\n",
    "answer = Dropout(0.5)(answer)\n",
    "answer = Dense(vocab_size)(answer)  # (samples, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TboZRHW3a5uU"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\piyus\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 1/50\n",
      "10000/10000 [==============================] - 12s 1ms/step - loss: 0.8510 - accuracy: 0.5039 - val_loss: 0.6959 - val_accuracy: 0.4970\n",
      "Epoch 2/50\n",
      "10000/10000 [==============================] - 5s 520us/step - loss: 0.7003 - accuracy: 0.5075 - val_loss: 0.6936 - val_accuracy: 0.4970\n",
      "Epoch 3/50\n",
      "10000/10000 [==============================] - 5s 502us/step - loss: 0.6949 - accuracy: 0.5071 - val_loss: 0.6894 - val_accuracy: 0.4970\n",
      "Epoch 4/50\n",
      "10000/10000 [==============================] - 5s 509us/step - loss: 0.5790 - accuracy: 0.7042 - val_loss: 0.4973 - val_accuracy: 0.7750\n",
      "Epoch 5/50\n",
      "10000/10000 [==============================] - 5s 503us/step - loss: 0.4825 - accuracy: 0.7941 - val_loss: 0.4479 - val_accuracy: 0.7950\n",
      "Epoch 6/50\n",
      "10000/10000 [==============================] - 5s 496us/step - loss: 0.4468 - accuracy: 0.8140 - val_loss: 0.4405 - val_accuracy: 0.8240\n",
      "Epoch 7/50\n",
      "10000/10000 [==============================] - 5s 517us/step - loss: 0.4114 - accuracy: 0.8337 - val_loss: 0.4148 - val_accuracy: 0.8070\n",
      "Epoch 8/50\n",
      "10000/10000 [==============================] - 5s 496us/step - loss: 0.3922 - accuracy: 0.8413 - val_loss: 0.3859 - val_accuracy: 0.8360\n",
      "Epoch 9/50\n",
      "10000/10000 [==============================] - 5s 487us/step - loss: 0.3746 - accuracy: 0.8479 - val_loss: 0.3795 - val_accuracy: 0.8360\n",
      "Epoch 10/50\n",
      "10000/10000 [==============================] - 5s 511us/step - loss: 0.3600 - accuracy: 0.8530 - val_loss: 0.3664 - val_accuracy: 0.8400\n",
      "Epoch 11/50\n",
      "10000/10000 [==============================] - 5s 497us/step - loss: 0.3430 - accuracy: 0.8562 - val_loss: 0.3487 - val_accuracy: 0.8440\n",
      "Epoch 12/50\n",
      "10000/10000 [==============================] - 5s 529us/step - loss: 0.3331 - accuracy: 0.8654 - val_loss: 0.3601 - val_accuracy: 0.8440\n",
      "Epoch 13/50\n",
      "10000/10000 [==============================] - 5s 502us/step - loss: 0.3241 - accuracy: 0.8683 - val_loss: 0.3944 - val_accuracy: 0.8400\n",
      "Epoch 14/50\n",
      "10000/10000 [==============================] - 5s 520us/step - loss: 0.3165 - accuracy: 0.8713 - val_loss: 0.3742 - val_accuracy: 0.8280\n",
      "Epoch 15/50\n",
      "10000/10000 [==============================] - 5s 508us/step - loss: 0.3038 - accuracy: 0.8757 - val_loss: 0.3969 - val_accuracy: 0.8300\n",
      "Epoch 16/50\n",
      "10000/10000 [==============================] - 5s 505us/step - loss: 0.3008 - accuracy: 0.8796 - val_loss: 0.3305 - val_accuracy: 0.8640\n",
      "Epoch 17/50\n",
      "10000/10000 [==============================] - 5s 508us/step - loss: 0.2882 - accuracy: 0.8815 - val_loss: 0.3457 - val_accuracy: 0.8510\n",
      "Epoch 18/50\n",
      "10000/10000 [==============================] - 5s 495us/step - loss: 0.2792 - accuracy: 0.8901 - val_loss: 0.3218 - val_accuracy: 0.8630\n",
      "Epoch 19/50\n",
      "10000/10000 [==============================] - 5s 516us/step - loss: 0.2630 - accuracy: 0.8952 - val_loss: 0.3072 - val_accuracy: 0.8700\n",
      "Epoch 20/50\n",
      "10000/10000 [==============================] - 5s 490us/step - loss: 0.2397 - accuracy: 0.9034 - val_loss: 0.2934 - val_accuracy: 0.8870\n",
      "Epoch 21/50\n",
      "10000/10000 [==============================] - 5s 501us/step - loss: 0.2099 - accuracy: 0.9149 - val_loss: 0.2486 - val_accuracy: 0.8950\n",
      "Epoch 22/50\n",
      "10000/10000 [==============================] - 5s 535us/step - loss: 0.1896 - accuracy: 0.9275 - val_loss: 0.2573 - val_accuracy: 0.8800\n",
      "Epoch 23/50\n",
      "10000/10000 [==============================] - 5s 516us/step - loss: 0.1766 - accuracy: 0.9312 - val_loss: 0.2995 - val_accuracy: 0.9050\n",
      "Epoch 24/50\n",
      "10000/10000 [==============================] - 5s 504us/step - loss: 0.1667 - accuracy: 0.9347 - val_loss: 0.2184 - val_accuracy: 0.9120\n",
      "Epoch 25/50\n",
      "10000/10000 [==============================] - 5s 525us/step - loss: 0.1574 - accuracy: 0.9388 - val_loss: 0.2361 - val_accuracy: 0.9180\n",
      "Epoch 26/50\n",
      "10000/10000 [==============================] - 5s 533us/step - loss: 0.1418 - accuracy: 0.9437 - val_loss: 0.2460 - val_accuracy: 0.9190\n",
      "Epoch 27/50\n",
      "10000/10000 [==============================] - 5s 504us/step - loss: 0.1339 - accuracy: 0.9503 - val_loss: 0.3827 - val_accuracy: 0.8660\n",
      "Epoch 28/50\n",
      "10000/10000 [==============================] - 5s 486us/step - loss: 0.1301 - accuracy: 0.9511 - val_loss: 0.2077 - val_accuracy: 0.9330\n",
      "Epoch 29/50\n",
      "10000/10000 [==============================] - 5s 477us/step - loss: 0.1197 - accuracy: 0.9565 - val_loss: 0.3307 - val_accuracy: 0.8720\n",
      "Epoch 30/50\n",
      "10000/10000 [==============================] - 5s 485us/step - loss: 0.1131 - accuracy: 0.9569 - val_loss: 0.2676 - val_accuracy: 0.9250\n",
      "Epoch 31/50\n",
      "10000/10000 [==============================] - 5s 513us/step - loss: 0.1096 - accuracy: 0.9606 - val_loss: 0.2464 - val_accuracy: 0.90100.95 - ETA: 0s -\n",
      "Epoch 32/50\n",
      "10000/10000 [==============================] - 5s 494us/step - loss: 0.1046 - accuracy: 0.9624 - val_loss: 0.3092 - val_accuracy: 0.8920\n",
      "Epoch 33/50\n",
      "10000/10000 [==============================] - 5s 514us/step - loss: 0.0971 - accuracy: 0.9659 - val_loss: 0.2804 - val_accuracy: 0.9090\n",
      "Epoch 34/50\n",
      "10000/10000 [==============================] - 5s 499us/step - loss: 0.0947 - accuracy: 0.9640 - val_loss: 0.2310 - val_accuracy: 0.9280\n",
      "Epoch 35/50\n",
      "10000/10000 [==============================] - 5s 526us/step - loss: 0.0890 - accuracy: 0.9668 - val_loss: 0.2182 - val_accuracy: 0.9260\n",
      "Epoch 36/50\n",
      "10000/10000 [==============================] - 5s 515us/step - loss: 0.0875 - accuracy: 0.9692 - val_loss: 0.2122 - val_accuracy: 0.9350\n",
      "Epoch 37/50\n",
      "10000/10000 [==============================] - 5s 520us/step - loss: 0.0791 - accuracy: 0.9720 - val_loss: 0.2277 - val_accuracy: 0.9330\n",
      "Epoch 38/50\n",
      "10000/10000 [==============================] - 5s 481us/step - loss: 0.0757 - accuracy: 0.9730 - val_loss: 0.2438 - val_accuracy: 0.9170\n",
      "Epoch 39/50\n",
      "10000/10000 [==============================] - 5s 504us/step - loss: 0.0717 - accuracy: 0.9747 - val_loss: 0.2723 - val_accuracy: 0.9270\n",
      "Epoch 40/50\n",
      "10000/10000 [==============================] - 5s 502us/step - loss: 0.0651 - accuracy: 0.9779 - val_loss: 0.2721 - val_accuracy: 0.9150\n",
      "Epoch 41/50\n",
      "10000/10000 [==============================] - 5s 503us/step - loss: 0.0655 - accuracy: 0.9761 - val_loss: 0.2526 - val_accuracy: 0.9360\n",
      "Epoch 42/50\n",
      "10000/10000 [==============================] - 5s 510us/step - loss: 0.0654 - accuracy: 0.9774 - val_loss: 0.2911 - val_accuracy: 0.9320\n",
      "Epoch 43/50\n",
      "10000/10000 [==============================] - 5s 506us/step - loss: 0.0568 - accuracy: 0.9797 - val_loss: 0.2416 - val_accuracy: 0.9320\n",
      "Epoch 44/50\n",
      "10000/10000 [==============================] - 5s 500us/step - loss: 0.0521 - accuracy: 0.9810 - val_loss: 0.2600 - val_accuracy: 0.9270\n",
      "Epoch 45/50\n",
      "10000/10000 [==============================] - 5s 524us/step - loss: 0.0528 - accuracy: 0.9811 - val_loss: 0.2394 - val_accuracy: 0.9330\n",
      "Epoch 46/50\n",
      "10000/10000 [==============================] - 5s 508us/step - loss: 0.0471 - accuracy: 0.9836 - val_loss: 0.3639 - val_accuracy: 0.9120\n",
      "Epoch 47/50\n",
      "10000/10000 [==============================] - 5s 539us/step - loss: 0.0440 - accuracy: 0.9847 - val_loss: 0.2955 - val_accuracy: 0.9260\n",
      "Epoch 48/50\n",
      "10000/10000 [==============================] - 5s 520us/step - loss: 0.0455 - accuracy: 0.9845 - val_loss: 0.2928 - val_accuracy: 0.9200\n",
      "Epoch 49/50\n",
      "10000/10000 [==============================] - 5s 491us/step - loss: 0.0404 - accuracy: 0.9847 - val_loss: 0.3107 - val_accuracy: 0.9250\n",
      "Epoch 50/50\n",
      "10000/10000 [==============================] - 5s 511us/step - loss: 0.0406 - accuracy: 0.9859 - val_loss: 0.3368 - val_accuracy: 0.9310\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1f6d72bb358>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO :Output a probability distribution over the vocabulary\n",
    "\n",
    "answer = Activation('softmax')(answer)\n",
    "\n",
    "# build the final model\n",
    "model = Model([input_sequence, question], answer)\n",
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# TODO: Train Model\n",
    "model.fit([inputs_train, queries_train], answers_train,\n",
    "          batch_size=32,\n",
    "          epochs=50,\n",
    "          validation_data=([inputs_test, queries_test], answers_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UywAOEZsa5uW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 156)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 6)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       multiple             11400       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_3 (Sequential)       (None, 6, 300)       11400       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 156, 6)       0           sequential_1[1][0]               \n",
      "                                                                 sequential_3[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 156, 6)       0           dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       multiple             228         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 156, 6)       0           activation_1[0][0]               \n",
      "                                                                 sequential_2[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "permute_1 (Permute)             (None, 6, 156)       0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 6, 456)       0           permute_1[0][0]                  \n",
      "                                                                 sequential_3[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           62592       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 32)           0           lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 38)           1254        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 38)           0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 86,874\n",
      "Trainable params: 86,874\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z3CRWdPHa5uj"
   },
   "source": [
    "### Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TnL6K44la5uk"
   },
   "outputs": [],
   "source": [
    "filename = 'chatbot_50_epochs.h5'\n",
    "model.save(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GgakiyWWa5up"
   },
   "source": [
    "## Evaluating the Model\n",
    "\n",
    "### Plotting Out Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "colab_type": "code",
    "id": "sZSqC83Ca5uq",
    "outputId": "c25e493e-66f0-45c9-f8b9-80723fd3ea8e"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# Plot out training history here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tj239SG3a5uv"
   },
   "source": [
    "### Evaluating on Given Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tG8ZLcDfa5uw"
   },
   "outputs": [],
   "source": [
    "model.load_weights(filename)\n",
    "\n",
    "# TODO: Predict with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "SRvzvWb2a5uz",
    "outputId": "b072d6cc-b829-40af-b248-6fd430e2f5c1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mary',\n",
       " 'got',\n",
       " 'the',\n",
       " 'milk',\n",
       " 'there',\n",
       " '.',\n",
       " 'John',\n",
       " 'moved',\n",
       " 'to',\n",
       " 'the',\n",
       " 'bedroom',\n",
       " '.']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3LgMpkBja5u3",
    "outputId": "d35fbf07-a0e7-4a6f-d3db-9f3a3a7a2f12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mary got the milk there . John moved to the bedroom .\n"
     ]
    }
   ],
   "source": [
    "story =' '.join(word for word in test_data[0][0])\n",
    "print(story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "oxCoLIzIa5u6",
    "outputId": "6cd2b94a-f9d5-4793-be63-5768fc250be7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is John in the kitchen ?\n"
     ]
    }
   ],
   "source": [
    "query = ' '.join(word for word in test_data[0][1])\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "jTvBcWB7a5vD",
    "outputId": "58f4e425-4912-423d-ed21-d9373e71272c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Test Answer from Data is: no\n"
     ]
    }
   ],
   "source": [
    "print(\"True Test Answer from Data is:\",test_data[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata = [(story.split(),query.split(),'no')]\n",
    "my_story,my_ques,my_ans = vectorize_stories(mydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_results = model.predict(([ my_story, my_ques]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "c0_qxIIma5vF",
    "outputId": "e85171e2-1259-4f9d-8c2a-e4446ab38558"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted answer is:  no\n",
      "Probability of certainty was:  1.0\n"
     ]
    }
   ],
   "source": [
    "#Generate prediction from model\n",
    "val_max = np.argmax(pred_results[0])\n",
    "\n",
    "for key, val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "\n",
    "print(\"Predicted answer is: \", k)\n",
    "print(\"Probability of certainty was: \", pred_results[0][val_max])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SyI57TGTa5vH"
   },
   "source": [
    "## Writing Your Own Stories and Questions\n",
    "\n",
    "Remember you can only use words from the existing vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 646
    },
    "colab_type": "code",
    "id": "x3oQ622ea5vH",
    "outputId": "ab6fd300-6e5e-405f-bf1a-c659859ba966"
   },
   "outputs": [],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "dX0qU6cZa5vL",
    "outputId": "a7ed0cc0-c598-463c-c952-a3642782730c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['John',\n",
       " 'left',\n",
       " 'the',\n",
       " 'kitchen',\n",
       " '.',\n",
       " 'Sandra',\n",
       " 'dropped',\n",
       " 'the',\n",
       " 'football',\n",
       " 'in',\n",
       " 'the',\n",
       " 'garden',\n",
       " '.']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note the whitespace of the periods\n",
    "my_story = \"John left the kitchen . Sandra dropped the football in the garden .\"\n",
    "my_story.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C4Lnyvbma5vO"
   },
   "outputs": [],
   "source": [
    "my_question = \"Is the football in the garden ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "AORXcLrta5vQ",
    "outputId": "ebc98349-6d5c-40b2-b84e-df7e559b80c1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Is', 'the', 'football', 'in', 'the', 'garden', '?']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_question.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mI7v0oHna5vS"
   },
   "outputs": [],
   "source": [
    "mydata = [(my_story.split(),my_question.split(),'yes')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eWuzBxsUa5vU"
   },
   "outputs": [],
   "source": [
    "my_story,my_ques,my_ans = vectorize_stories(mydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-BX98BWha5vX"
   },
   "outputs": [],
   "source": [
    "pred_results = model.predict(([ my_story, my_ques]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "erFlHtPba5va",
    "outputId": "28319f97-81c0-409d-ec53-1f11ff775992"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted answer is:  yes\n",
      "Probability of certainty was:  0.8124105\n"
     ]
    }
   ],
   "source": [
    "#Generate prediction from model\n",
    "val_max = np.argmax(pred_results[0])\n",
    "\n",
    "for key, val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "\n",
    "print(\"Predicted answer is: \", k)\n",
    "print(\"Probability of certainty was: \", pred_results[0][val_max])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reference Links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://adventuresinmachinelearning.com/word2vec-keras-tutorial/\n",
    "- https://arxiv.org/pdf/1503.08895.pdf\n",
    "- https://arxiv.org/pdf/1502.05698.pdf\n",
    "- https://research.fb.com/downloads/babi/"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "02-Chat-Bots-CHALLENGE.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
